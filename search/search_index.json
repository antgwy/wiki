{"config":{"lang":["en"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"]},"docs":[{"location":"","title":"wtyang's wiki","text":"<p>\u8fd9\u91cc\u662f wtyang \u7684 wiki page\uff0c\u7528\u6765\u8bb0\u5f55\u4e00\u4e9b\u9700\u8981\u67e5\u9605\u7528\u5f97\u5230\u7684\u77e5\u8bc6\u3002\u7531 MkDocs \u6784\u5efa\u3002</p>"},{"location":"#_1","title":"\u7528\u6cd5","text":"<p>The HTML specification is maintained by the W3C.</p> <p>Info</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> bubble_sort.py<pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre> <pre><code>def bubble_sort(items):\n    for i in range(len(items)):\n        for j in range(len(items) - 1 - i):\n            if items[j] &gt; items[j + 1]:\n                items[j], items[j + 1] = items[j + 1], items[j]\n</code></pre> CC++ <pre><code>#include &lt;stdio.h&gt;\n\nint main(void) {\n  printf(\"Hello world!\\n\");\n  return 0;\n}\n</code></pre> <pre><code>#include &lt;iostream&gt;\n\nint main(void) {\n  std::cout &lt;&lt; \"Hello world!\" &lt;&lt; std::endl;\n  return 0;\n}\n</code></pre> <p>\u56fe\u7247</p> \u56fe\u7247\u5c45\u5de6\u56fe\u7247\u5c45\u53f3 Image, aligned to left<pre><code>![Image title](https://dummyimage.com/600x400/eee/aaa){ align=left }\n</code></pre> Image, aligned to right<pre><code>![Image title](https://dummyimage.com/600x400/eee/aaa){ align=right }\n</code></pre> <pre><code>erDiagram\n  CUSTOMER ||--o{ ORDER : places\n  ORDER ||--|{ LINE-ITEM : contains\n  CUSTOMER }|..|{ DELIVERY-ADDRESS : uses</code></pre>"},{"location":"java/","title":"Java","text":"<p>JavaGuide</p> <pre><code>ArrayList&lt;String&gt; listOfStrings = new ArrayList&lt;&gt;();\n</code></pre>"},{"location":"diffusion/code/","title":"Code","text":"<pre><code>def load_model_from_config(config, ckpt, verbose=False):\n    print(f\"Loading model from {ckpt}\")\n    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n    if \"global_step\" in pl_sd:\n        print(f\"Global Step: {pl_sd['global_step']}\")\n    sd = pl_sd[\"state_dict\"]\n    model = instantiate_from_config(config.model)\n    m, u = model.load_state_dict(sd, strict=False)\n    if len(m) &gt; 0 and verbose:\n        print(\"missing keys:\")\n        print(m)\n    if len(u) &gt; 0 and verbose:\n        print(\"unexpected keys:\")\n        print(u)\n\n    model.cuda()\n    model.eval()\n    return model\n</code></pre>"},{"location":"diffusion/paper/guide/","title":"\u8bba\u6587\u9605\u8bfb","text":""},{"location":"diffusion/paper/guide/#_2","title":"\u5fc5\u8bfb","text":"<ul> <li>\u7b2c 0 \u7bc7\uff1a[Deep Unsupervised Learning using Nonequilibrium  Thermodynamics]</li> </ul>"},{"location":"diffusion/paper/guide/#ddpm","title":"DDPM","text":"<ul> <li>DDPM: [Denoising Diffusion Probabilistic Models]<ul> <li>[Improved Denoising Diffusion Probabilistic Models] (ICML 2021)</li> </ul> </li> </ul>"},{"location":"diffusion/paper/guide/#ddim","title":"DDIM","text":"<ul> <li>DDIM: [Denoising Diffusion Implicit Models]</li> <li>SDE: [Score-Based Generative Modeling through Stochastic Differential Equations]<ul> <li>\u524d\u7f6e\uff1a [Generative Modeling by Estimating Gradients of the Data Distribution]</li> </ul> </li> <li>LDM: [High-Resolution Image Synthesis with Latent Diffusion Models]</li> </ul>"},{"location":"diffusion/paper/guide/#_3","title":"\u57fa\u7840","text":"<ul> <li>\u641e\u61c2\u4e4b\u540e\u53ef\u4ee5\u590d\u73b0\u5982\u4f55\u901a\u8fc7 Classifier-Guided \u548c Classifier-Free \u6765\u63a7\u5236\u751f\u6210</li> <li>Classifier-Guided: [Diffusion Models Beat GANs on Image Synthesis]</li> <li> <p>Classifier-Free: [Classifier-Free Diffusion Guidance]</p> </li> <li> <p>Imagen: [Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding]</p> </li> <li>[DALL-E 2]</li> <li> <p>[DALL-E 3]</p> </li> <li> <p>\u641e\u61c2\u540e\u53ef\u4ee5\u63a2\u7d22\u5982\u4f55\u5fae\u8c03\u73b0\u6709 diffusion model\uff0c\u5bf9\u5176\u6ce8\u5165\u7279\u5b9a\u7684\u6982\u5ff5</p> </li> <li>DreamBooth: [DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation]</li> <li>LoRA: [LoRA: Low-Rank Adaptation of Large Language Models]</li> <li>Textual Inversion: [An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion]</li> <li>\u518d\u63a2\u7a76\u5982\u4f55\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u63a7\u5236</li> <li> <p>ControlNet: [Adding Conditional Control to Text-to-Image Diffusion Models]</p> </li> <li> <p>Transformer DiT: [Scalable Diffusion Models with Transformers]</p> </li> <li> <p>[Inversion]: [Null-text Inversion for Editing Real Images using Guided Diffusion Models]</p> </li> <li> <p>\u5206\u7c7b\u4e2d\u7684\u5e94\u7528\uff1a</p> </li> <li> <p>[Your Diffusion Model is Secretly a Zero-Shot Classifier]</p> </li> <li> <p>[Identity Preserving]</p> </li> <li> <p>https://github.com/xuekt98/readed-papers/tree/main</p> </li> <li> <p>tutorials: https://geometry.cs.ucl.ac.uk/courses/diffusion4VC_eg24/</p> </li> </ul>"}]}